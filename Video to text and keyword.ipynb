{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c22428-0fc9-4a51-bac4-914dc92fbefb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio_.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Why even good programmers fail coding interviews. First reason people fail coding interviews is because they spend too much time solving very easy or very hard problems. In reality, most problems asked in the interviews are going to be of medium difficulty. Second reason people fail coding interviews is because they don't time box their practice sessions. The actual interview is usually only 45 minutes, but people spend hours solving one problem in the practice sessions. Third reason people fail coding interviews is because they don't use their interviewer enough to use your interviewer effectively. Clearly explain your answer to the interviewer in the beginning so that they can correct you. You don't want to end up in a situation where you have coded up the wrong algorithm and there are only five minutes left in the interview. Most common reason why people fail coding interviews is because they worry too much about the things that are outside their circle of control. Checking your interviewer's LinkedIn profile to see if he or she is a senior engineer or not is not going to help you, and you can't control it anyway. That's.\n",
      "reason - situation - sessions - circle - engineer - beginning - control - time - interviews - problems - practice - reality - difficulty - interviewer - hours - programmers - answer - algorithm - things - interview - problem - people - profile - minutes\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import AudioFileClip\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from tkinter import ttk\n",
    "from fpdf import FPDF\n",
    "import assemblyai as aai\n",
    "import threading\n",
    "import speech_recognition as sr\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import os\n",
    "from docx import Document\n",
    "import en_core_web_sm\n",
    "#variables\n",
    "video_clip = ''\n",
    "audio_clip = ''\n",
    "#api key\n",
    "aai.settings.api_key = f\"21f1e0326c544c6081112fb5d6091b89\"\n",
    "#function to get video\n",
    "def get_video():\n",
    "    global video_filepath, video_clip\n",
    "    try:\n",
    "        video_filepath.set(filedialog.askopenfilename(title=\"Select your video file\"))\n",
    "        video_clip = VideoFileClip(str(video_filepath.get()))\n",
    "    except:\n",
    "        messagebox.showerror(\"Error\", \"No video selected\")\n",
    "#function to convert audio to pdf\n",
    "def audio_to_pdf():\n",
    "    global audio_clip\n",
    "    try :\n",
    "        #extract audio\n",
    "        audio_clip = video_clip.audio.write_audiofile(r\"audio.wav\")\n",
    "        transcriber = aai.Transcriber()\n",
    "        transcript = transcriber.transcribe(\"audio.wav\")\n",
    "        t=transcript.text  \n",
    "        print(t)\n",
    "        # Load the English language model\n",
    "        # Load the English language model\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        # Define the list of part-of-speech tags you want to include\n",
    "        pos_tag = ['PROPN', 'NOUN']\n",
    "        # Process the text with spaCy\n",
    "        doc = nlp(t.lower())\n",
    "        # Initialize an empty list to store the keywords\n",
    "        re = []\n",
    "        # Iterate through tokens in the processed text\n",
    "        for token in doc:\n",
    "            # Check if the token is not a stop word and not in punctuation\n",
    "            if token.text not in nlp.Defaults.stop_words and token.text not in punctuation:\n",
    "                # Check if the token's part-of-speech tag is in the specified list\n",
    "                if token.pos_ in pos_tag:\n",
    "                    re.append(token.text)\n",
    "        o = ' - '.join(set(re))\n",
    "        print(o)\n",
    "\n",
    "\n",
    "\n",
    "        messagebox.showinfo(\"Message\", \"Conversion Successfull\")\n",
    "    except :\n",
    "        messagebox.showerror( \"Error\", \"Conversion not performed\")\n",
    "    \n",
    "\n",
    "\n",
    "    d = Document()\n",
    "    # Add content to the document\n",
    "    d.add_paragraph(t)\n",
    "    d.add_paragraph(o)\n",
    "    # Save the document as a .docx file\n",
    "    d.save('document.docx')\n",
    "#function to run the script\n",
    "def run():\n",
    "    global progress_bar\n",
    "    t1 = threading.Thread(target = progress_bar.start)\n",
    "    t2 = threading.Thread(target = audio_to_pdf)\n",
    "    t2.start()\n",
    "    t1.start()\n",
    "# GUI CODE starts\n",
    "# Intializing main program settings\n",
    "root = Tk()\n",
    "root.title(\"Summaries Converter\")\n",
    "# Variables for file paths\n",
    "video_filepath = StringVar()\n",
    "# Creating UI Frame\n",
    "UI_frame = Frame(root, width=500, height=500, relief = \"raised\")\n",
    "UI_frame.grid(row=0, column=0)\n",
    "convert_frame = Frame(root, width=500, height=500, relief=\"raised\")\n",
    "convert_frame.grid(row=1, column=0)\n",
    "# Labels and buttons\n",
    "select = Label(UI_frame, text=\"Select Video : \", font = (\"Arial\", 12))\n",
    "select.grid(row=1, column=1, padx=5, pady=5, sticky=W)\n",
    "browse = Button(UI_frame, text=\"Browse\", command = get_video, font = (\"Arial\", 12))\n",
    "browse.grid(row=1, column=2, padx=5, pady=5)\n",
    "video_selected = Label(UI_frame, text = \"Selected video : \",  font = (\"Arial\", 12))\n",
    "video_selected.grid(row = 2, column = 1, padx = 5, pady = 5, sticky = E)\n",
    "video_path = Label(UI_frame, textvariable=video_filepath)\n",
    "video_path.grid(row=2, column=2, padx=2, pady=5, sticky=W)\n",
    "convert = Button(convert_frame, text=\"Convert\", command = run,  font = (\"Arial\", 12))\n",
    "convert.grid(row=3, column=1, pady=5)\n",
    "progress_bar = ttk.Progressbar(root, orient=HORIZONTAL, mode='indeterminate', length=500)\n",
    "progress_bar.grid(padx=25, pady=25)\n",
    "# Calling main program\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336275a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio_reference.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription Accuracy: 92.97297297297298 %\n"
     ]
    }
   ],
   "source": [
    "# import speech_recognition as sr\n",
    "import assemblyai as aai\n",
    "import threading\n",
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "# Function to calculate transcription accuracy\n",
    "def calculate_accuracy(transcribed_text, reference_audio_path):\n",
    "    # Recognize audio from file\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(reference_audio_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    # Transcribe audio using Google Speech-to-Text\n",
    "    reference_transcript = recognizer.recognize_google(audio_data)\n",
    "\n",
    "    # Convert both texts to lowercase\n",
    "    transcribed_text = transcribed_text.lower()\n",
    "    reference_transcript = reference_transcript.lower()\n",
    "\n",
    "    # Split the texts into words\n",
    "    transcribed_words = transcribed_text.split()\n",
    "    reference_words = reference_transcript.split()\n",
    "\n",
    "    # Calculate the number of correct words\n",
    "    correct_words = 0\n",
    "    for transcribed_word in transcribed_words:\n",
    "        if transcribed_word in reference_words:\n",
    "            correct_words += 1\n",
    "\n",
    "    # Calculate the accuracy percentage\n",
    "    accuracy = (correct_words / len(reference_words)) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Main function to run the script\n",
    "def main():\n",
    "    # Extract audio from video\n",
    "    audio_clip = AudioFileClip(\"audio_.wav\")\n",
    "    audio_clip.write_audiofile(\"audio_reference.wav\")\n",
    "\n",
    "    # Transcribe audio using AssemblyAI\n",
    "    transcriber = aai.Transcriber()\n",
    "    transcript = transcriber.transcribe(\"audio_.wav\")\n",
    "    transcribed_text = transcript.text\n",
    "\n",
    "    # Calculate transcription accuracy\n",
    "    accuracy = calculate_accuracy(transcribed_text, \"audio_reference.wav\")\n",
    "    print(\"Transcription Accuracy:\", accuracy, \"%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f878e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
